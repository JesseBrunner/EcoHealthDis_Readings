---
title: "Dose dependence in infections"
subtitle: "_Everything_ is quantitative"
author: "Jesse Brunner"
date: "`r Sys.Date()`"
output: tint::tintPdf
latexfonts:
  - package: newtxmath
    options: 
      - cmintegrals
      - cmbraces
  - package: ebgaramond-maths
header-includes:
   - \usepackage{booktabs}
   - \usepackage{cancel}
---

```{r setup, include=FALSE}
library(tufte)
library(knitr)
# invalidate cache when the tufte version changes
opts_chunk$set(tidy = FALSE, 
                      message = FALSE, 
                      warning = FALSE,
                      echo = FALSE)
options(htmltools.dir.version = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(scales) # for prettier axis labels
library(simecol) # for running model 
library(scales) # for prettier axis labels

theme_set(theme_minimal())
```

# Dose-dependent infections

```{r, fig.margin=TRUE, fig.cap="A hypothetical dose response."}
tibble(Dose = 10^seq(0,5, length.out = 101), 
       Response = 1-exp(-0.0001*Dose)) %>% 
  ggplot(., aes(Dose, Response)) + 
  geom_line() + 
  scale_x_log10(breaks = 10^c(0:5),
                      labels = label_comma(accuracy=1)) + 
  labs(x="Dose of something", y="Proportion responding somehow\n(e.g., infected, dead)")
```

You may have heard the phrase, "the dose makes the poison." Attributed to Paracelcus^["All things are poison, and nothing is without poison, the dosage alone makes it so a thing is not a poison." -Paracelsus], this maxim expresses a basic principle in toxicology that negative effects increase with the amount or concentration of some potentially harmful substance^[And the reverse is also true. [The dose also makes the cure!](https://www.canr.msu.edu/news/everyday-toxicology-digging-deeper-the-dose-makes-the-poison-the-cure)]. A staple experiment in toxicology is thus, not surprisingly, the dose-response experiment in which groups of organisms are exposed to one of a series of increasing doses of the chemical of interest, usually spanning several orders of magnitude, and the outcome (e.g., death) is observed. Usually there is some sort of sigmoidal (S-shaped) relationship where nothing much happens at low doses and a response (e.g., becoming sick or dying) increases to  a virtual certainty at high enough doses. Note that this relationship is usually sigmoidal only on a logarithmic x-axis. Doubling the dose does not double the probability of a response, but increasing the dose 10-fold might. 


```{r, fig.margin = TRUE,  fig.cap="A real dose-response relationship. The proportion of salamander larvae that (a) became infected, (b) died if infected, and (c) had infections if survived. From Brunner et al. 2005. "}

include_graphics("Dose_ATV.png", dpi=600)
```

Those of us interested in infections with parasites also use dose-response experiments to determine how many or few parasites it takes to ensure an infection (or disease or death), to compare the infectiousness of different strains of parasites or host populations, and more. For instance, one of my [first papers](https://www.researchgate.net/publication/7849160_Brunner_JL_Richards_K_Collins_JP_Dose_and_host_characteristics_influence_virulence_of_ranavirus_infections_Oecologia_144_399-406) in graduate school was from a dose-response experiment with tiger salamander larvae (_Ambystoma mavortium_ [formerly _tigrinum_] _nebulosum_) exposed to a ranavirus, ATV. 

As is typical, the proportion of larvae that were infected increased with the dose of virus^[PFU is short for "plaque-forming units" and is a measure of infectious virus particles.] to which they were exposed. We can use this information to find the dose at which an individual has a 50% chance of becoming infected, which is usually abbreviated as the $ID_{50}$, though we could just as easily find the $ID_{10}$ or the $ID_{90}$. It is just a common metric to summarize the median, though we will see some biological meaning, too, below. You will also see that there was an increased chance of dying, given an infection, with higher doses. (And you can find the $LD_{50}$ or the dose that kills half the individuals.) I will return to mortality below, but for now let us focus on the probability of becoming infected as a function of dose. 

Why does this happen? I mean, it makes some intuitive sense, but what is the underlying explanation? I will offer two (related) ways of thinking about this.

## The single-hit model

Let us assume that each virus particle in the water has some very small probability of causing an infection over the course of the experiment (e.g., in a 24h exposure). It might be something like a 1 in 10,000 chance, so if there is only one virion in the water, the larva would be virtually assured of not being infected; a probability of 0.0001 of being infected and a probability of 0.9999 of remaining uninfected. What if there were _two_ virus particles. You might think that the probability of infection goes from 1 in 10,000 to 2 in 10,000 for a probability of becoming infected of 0.0002, but actually, no^[Well, actually, this is approximately correct, but only because the chance of being infected by both virions is so vanishingly small. If the probabilities of infection were higher or we were using many more virions this perhaps intuitive approach will fail.]. 

The reason why is that individual might be infected by either virion or both, either ever way produces the same outcome. So instead we need to think about the probability of escaping infection from the first virion _and_ the second virion, and then subtract that from one. Whenever we are dealing with the probability of two independent events happening (escaping both virions) we multiply those probabilities. So the probability of becoming infected given two virions is one minus the probability of both virions failing:
$$
P(\text{infected} | 2) = 1-(1-0.0001)\times(1-0.0001) = 1-0.9999 \times 0.9999 
$$
and the probability of becoming infected with three virions would be one minus the probability of all three virions failing:
$$
P(\text{infected} | 3) = 1-(1-0.0001)\times(1-0.0001)\times(1-0.0001) = 1-0.9999 \times 0.9999 \times 0.9999
$$
Clearly this will get tedious if we go much further, so let us generalize. First, let us call the probability of an infection from a single virion $\phi$ and the probability of _not_ becoming infected is $(1-\phi)$. Second, notice that this probability of not becoming infected is multiplied by itself as many times as there are virions. Let's call the number of virions $x$. Thus, probability of infection given $d$ virions is:
$$
P(\text{infected} | d) = 1-(1-\phi)^d.
$$
With $\phi = 0.0001$ it would take 6,931 virions to have a 50% chance of the individual being infected. (Try plugging in some numbers.)

Usually we work with a continuous version of this model where $d$ can vary continuously:
$$
P(\text{infected} | d) = 1-e^{-\phi d}.
$$
It produces virtually the same results, but it has nicer mathematical properties. 

The dose-response curve from this example was seen in Figure 1, above. It is was what is known as a "single-hit" model because it only takes one "hit" to cause an infection. I like it because it shows that even if we assume that all individuals are identical, we _still_ expect some variation in outcome just because of stochasticity (i.e., random chance) in the amount of virus an individual is exposed to. Or in other words, we should expect sigmoidal dose-response relationships even without assuming any interesting biology. 


## An aside on dose-dependent detection

It is worth noting that we can think of most methods of detecting the parasite of interest (or antibodies to the parasite) in a sample in an analogous fashion. For instance, PCR reactions and their more sophisticated offshoots (e.g., Taqman real-time PCR used for most laboratory-based Covid-19 tests) can, in theory, detect a single copy of the target gene. In the real world, the actual efficiency of a test is somewhat lower. If we think about the _per copy_ of the target gene or antibody probability of detection as $\phi$^[Hopefully this per copy probability is much, much higher than our example with infection from a virus!] and $d$ as the number of copies in the sample, we can see that we may have trouble detecting low-level infections (low $d$), especially if there is some inhibitor that lowers $\phi$. 

On the flip side, you can see why pooling samples and running them together, may not have a huge impact on the probability of detection. If, say, four swabs are run together and only one is from an infected individual, then the $d$ copies in the sample are diluted to $d/4$, but that does not matter a great deal. For instance, if the sample had $d=100$ SARS-CoV-2 particles and $\phi = 0.5$, which I _hope_ is quite low, then the probability of detection would be reduced from a high of `r 1-exp(-0.5*100)` if run by itself to a low of `r 1-exp(-0.5*100/4)` in a pool of four. That is, the pooling hardly matters. In actual fact, sensitivity can be reduce by a non-negligible amount, but the ability to screen more samples quickly can outweigh this performance cost. Pooling is most often used to screen for rare infections---originally syphilis---in large populations, but is [beginning to be used in Covid-19 testing](https://www.nytimes.com/interactive/2020/07/27/upshot/coronavirus-pooled-testing.html).

## The tolerance model and heterogeneity in susceptibility 

```{r, fig.margin=TRUE, fig.show = 'hold', fig.cap="A hypothetical distribution of tolerances in a group of hosts (top) and the proportion of the group that would be infected (or die) if exposed to a given dose (bottom)."}
ggplot(data.frame(x=0:6), aes(x=x)) + 
  stat_function(fun=dnorm, args = list(mean=3, sd=1/2)) + 
  labs(x=expression(log[10]~Dose), y="Proportion of population\nwith tolerance threshold at dose")

ggplot(data.frame(x=0:6), aes(x=x)) + 
  stat_function(fun=pnorm, args = list(mean=3, sd=1/2)) +
  labs(x=expression(log[10]~Dose), y="Proportion of population\ninfected at dose")
```

Let us turn our thinking about infection on its head. What if we thought of the host and the amount or number of parasites that an individual can fight off before it succumbs and becomes infected. This results in what is called a tolerance model^[This approach comes from toxicology, especially calculating effective doses of insecticides. In this context the idea is that an individual can tolerate a given amount of the insecticide, but succumbs beyond that. Hence the term "tolerance" model.]. Let us assume that the population (e.g., salamander larvae) has a distribution of tolerances, a normal bell-shaped curve with a mean of $\mu$ virions (on a log-10 scale) and a standard deviation of $\sigma$. This means that half the population can withstand just under $\mu$ virions without becoming infected. This half-way point should correspond to the $ID_{50}$, the dose at which half the population is expected to become infected. At lower doses, the threshold amount of virus has not been exceed for nearly as many, but at higher doses the threshold is exceeded for a much larger fraction of the hosts. Hence, we get a classic, sigmoidal dose-response.

Now let us imagine that we study two populations with the same _average_ tolerance (or resistance) to the virus. The first is an inbred group of animals that are more alike, and thus less variable (smaller $\sigma$) while the second is a wild population of outbred animals that has much more variation among individuals (larger $\sigma$). As you would expect, the tolerance  distribution for the wild population is wider than for the inbred population, but as you might not have expected, you can actually see the outcome in a dose-response experiment. The wider distribution of tolerances results in a less-steep sigmoidal curve. Why is that? Hint, pick a point on the x-axis (e.g., 2), and think about what fraction of each population would succumb. Then pick another (e.g., 4) and repeat. 

```{r, fig.margin=TRUE, fig.show = 'hold', fig.cap="Tolerance distributions (top) and proportion infected at a given dose (bottom) for a highly inbred (red) and a more variable, outbred (blue) population."}
ggplot(data.frame(x=0:6), aes(x=x)) + 
  stat_function(fun=dnorm, args = list(mean=3, sd=1/4), color="red") + 
  stat_function(fun=dnorm, args = list(mean=3, sd=1), color="blue") + 
  labs(x=expression(log[10]~Dose), y="Proportion of population\nwith tolerance threshold at dose")

ggplot(data.frame(x=0:6), aes(x=x)) + 
  stat_function(fun=pnorm, args = list(mean=3, sd=1/4), color="red") +
  stat_function(fun=pnorm, args = list(mean=3, sd=1), color="blue") + 
  labs(x=expression(log[10]~Dose), y="Proportion of population\ninfected at dose")
```

So dose-response experiments tell us about the average response, as well as the distribution of responses. That is, it can tell us about the heterogeneity in susceptibility. What's more, this variation in susceptibility to infection can skew rates of transmission. Those individuals with low tolerances are very easily infected, and they can act as a wick for the infection, making it easier for an epidemic to take off. But on the flip side there are likely many individuals who never become infected because they have very high tolerances, which are unlikely to be exceeded during an epidemic. This effect, in and of itself, leads to saturating (plateauing) rates of transmission with increasing densities of infected hosts as we had seen when discussing transmission. 


# Dose-dependent outcomes

Just as in toxicological studies, individuals are more likely to die from exposure to higher doses of a pathogen, all else equal. That is in large measure because individuals are more likely to be infected, which is sort of a pre-requisite for death from infection. But, as you saw from my dose-response study with salamander larvae, case fatality rates also increase. That is, the probability of death _given_ an infection increases with dose^[They also die more quickly.]. Why is that?

The answer is complex and likely multifaceted, but we can gain a general insight by thinking about the growth of the parasite population ($P(t)$) within the host. Let us start by assuming that the virus grows exponentially at rate $r$. It probably does not run out of resources, at least not directly, and so this is not terribly unrealistic. Now for the unrealistic part. Let us imagine that the host is passive in response to the virus except that it dies when the virus population reaches some lethal threshold ($P_{lethal}$). Sure, the host's immune response certainly does respond after a fashion to slow viral growth and even clear the infection, but let us ignore that at first. Here's the important part: if the parasite population starts from a larger initial size ($P(0)$) it reaches that lethal threshold sooner. 


```{r, fig.margin=TRUE, fig.show="hold", fig.cap="Exponential growth of parasite populations within a host up to a lethal threshold, starting from various initial densities. "}

df <- expand.grid(time=0:30, P_0 = 10^(0:4))
df <- df %>% mutate(P_t = P_0*exp(0.5*time)) 

ggplot(df, aes(x=time, y=P_t, group = P_0)) + 
  geom_line() + 
  geom_hline(yintercept = 10^6) + 
  scale_y_continuous("Within host parasite population", 
                # breaks = 10^c(0:6), 
                labels = label_comma(accuracy=1))+
  coord_cartesian(ylim=c(1,1.2*10^6)) +
  annotate(geom="text", x=c(5, 8.25,13, 18, 22.25,26.75),
           y=500000, 
           label=c(expression(P(0) == ''),10^(4:0)), 
           hjust=0, cex=3) + 
  annotate(geom="text", x=0, y=10^6, label="Lethal level", hjust=0, vjust=-0.2)

ggplot(df, aes(x=time, y=P_t, group = P_0)) + 
  geom_line() + 
  geom_hline(yintercept = 10^6) + 
  scale_y_log10("Within host parasite population", 
                breaks = 10^c(0:6), 
                labels = label_comma(accuracy=1))+
  coord_cartesian(ylim=c(1,2*10^6))+
  annotate(geom="text", x=c(5, 8.25,13, 18, 22.25,26.75),
           y=500000, label=c(expression(P(0) == ''), 10^(4:0)), 
           hjust=0, cex=3) + 
  annotate(geom="text", x=0, y=10^6, label="Lethal level", hjust=0, vjust=-0.2)

```


For completeness, the model is:
$$
P(t) = P(0) e^{rt},
$$
essentially the exponential growth model with different letters. If we want to determine how long it takes to get to a lethal level we can substitute in $P_{lethal}$ for $P(t)$ and then solve for $t$.

\begin{equation*}
\begin{aligned}
P_{lethal} &= P(0) e^{rt} \\
\frac{P_{lethal}}{P(0)} &= e^{rt} \\
\ln\left( \frac{P_{lethal}}{P(0)} \right) &= rt \\
t &= \frac{ \ln\left( \frac{P_{lethal}}{P(0)} \right) } {r}
\end{aligned}
\end{equation*}

You can see that there are two ways to minimize the time (to a lethal level): 1) increase $r$ or 2) increase the initial population size $P(0)$. 

So the logic for dose-dependence in case fatality rates is this: with exposure to larger doses of the parasites, more parasites gain entry into the host, meaning they start growing from a larger initial population. This means that the parasite population more rapidly reaches a hypothetical lethal level. 

We can relax this lethal level idea and instead think about it this way. Parasite populations starting from a higher initial population size reach a greater size or density before the host's immune system really kicks into gear, which makes the parasite more difficult to control and more likely to be lethal (or cause morbidity). Or another way, larger doses give the parasite a head start.

# Final thoughts

* It is worth remembering that the epidemiological models we have seen usually do not include parasite dose anywhere^[With the exception of those describing transmission from the environment, where we keep track of the number or density of parasites in the environment.]. Rather, they track the number, density, or frequency of infected hosts in the population. This is equivalent to saying that every individual infected host is shedding the same number of parasites and every susceptible individual is equally susceptible. In some cases hosts might be similar enough that it does not matter, but I have a strong suspicion that a lot of the problems with epidemiological models would be resolved if only we more explicitly dealt with dose or intensity of infection. 

* Dose-response relationship, and the underlying logic of them, emphasize the _quantitative_ nature of many aspects of infections. Reducing one's exposure to infected people by some amount (e.g., going shopping half as often) does not guarantee that one does not become infected, but it can have a measurable impact on the chances of becoming infected. Indeed, this perspective helps make sense of some new research [suggesting masks can protect the wearer as well as those around the wearer](https://www.nytimes.com/2020/07/27/health/coronavirus-mask-protection.html). In [one forthcoming study](https://ucsf.app.box.com/s/blvolkp5z0mydzd82rjks4wyleagt036), susceptible hamsters were housed next to infected hamsters in a way that allowed virus-laden air to pass through. But when they were separated by a surgical mask, which presumably reduce, but do not eliminate the virus going between them, the susceptible hamsters were less likely to become infected and those that were had milder symptoms. Risk is not binary (yes/no, all or nothing) but continuous and we would do well to think about it that way.
