---
title: "The importance of heterogeneity"
subtitle: "Where all the hosts are above average"
author: "Jesse Brunner"
date: "`r Sys.Date()`"
output: tint::tintPdf
latexfonts:
  - package: newtxmath
    options: 
      - cmintegrals
      - cmbraces
  - package: ebgaramond-maths
header-includes:
   - \usepackage{booktabs}
   - \usepackage{cancel}
---

```{r setup, include=FALSE}
library(tufte)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(tidy = FALSE, 
                      message = FALSE, 
                      warning = FALSE,
                      echo = FALSE,
                      cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(scales) # for prettier axis labels
library(simecol) # for running model 
theme_set(theme_minimal())
```

One of the key assumptions we make when building an SIR model---indeed, often when talking about infection rates, case fatality, and so on more generally---is that individual hosts are essentially identical. Susceptible hosts are all equally likely to become infected given an infectious contact and all infected hosts are equally infectious to others. Or put another way, the population within a box ($S,I, \text{ or }R$) is homogeneous. 

Of course this is not true. Individual humans, elk, gypsy moths, corals, and so vary in myriad ways. They are of different ages, sexes, genetic backgrounds, physiological condition, social positions, prior histories of infections, and on-and-on. When we make this assumption of homogeneity are _not_ saying that these differences do not exist, but rather that across a population these differences more or less balance out. Sure, there are some individuals that are more easily infected, but there are also some that are more resistant and on average it does not matter a great deal. But some times there are important, perhaps glaringly obvious differences to do change things. 

# Adding boxes to account for differences

For instance, it is becoming increasingly clear that children are much less likely to get very sick with Covid-19 than adults, but what is more, children under 10 years of age also seem to spread the infection at half the rate as older kids and adults^[[With important implications for whether and how K-12 schools might open.](https://www.nytimes.com/2020/07/18/health/coronavirus-children-schools.html)]. By lumping younger kids with everyone else in the same boxes we are missing an important part of the epidemic might unfold. By using average values of transmission rates for the whole population together we would in essence overestimate the role of K-3 age children and underestimate the role of everyone else. What's more, younger children generally have very different patterns of contacts than the rest of the population. Their contacts are primarily with other young kids, especially during school, and they are unlikely to encounter more than a select few adults. What I am saying is that K-3 children are very different beasts from the rest of the population^[In more ways than these!] and so we might do well to treat them as such. 


```{r boxarrows, echo=FALSE, message=FALSE, fig.cap="Box and arrow diagram of an SIR model with distinct children ($k$) and adult ($a$) groups. Note that infections come both from one's own group and from the other.", fig.height=3}
library(diagram)

openplotmat()
# pos <- coordinates(c(7))
straightarrow(c(0.1, 0.9), c(0.4, 0.9), arr.pos = 1)
# straightarrow(c(0.12, 0.8), c(0.4, 0.3), arr.pos = 1)


straightarrow(c(0.1, 0.2), c(0.4, 0.2), arr.pos = 1)
# straightarrow(c(0.12, 0.3), c(0.4, 0.8), arr.pos = 1)

straightarrow(c(0.58, 0.9), c(0.8, 0.9), arr.pos = 1)
straightarrow(c(0.58, 0.2), c(0.8, 0.2), arr.pos = 1)

straightarrow(c(0.57, 0.8), c(0.65, 0.62), arr.pos = 1)
straightarrow(c(0.57, 0.3), c(0.65, 0.48), arr.pos = 1)


curvedarrow(c(0.42, 0.8), c(0.31, 0.25), arr.pos = 0.9, curve=0.05, endhead = TRUE, lty=3, lwd=0.75, arr.lwd=0.25, lcol="gray")
curvedarrow(c(0.42, 0.3), c(0.31, 0.65), arr.pos = 0.9, curve=-0.05, endhead = TRUE, lty=3, lwd=0.75, arr.lwd=0.25, lcol="darkgray")

textrect(c(0.07, 0.9), lab =expression(S[k]), radx = 0.05, rady = 0.1, cex = 1)
textrect(c(0.07, 0.2), lab =expression(S[a]), radx = 0.05, rady = 0.1, cex = 1)


textrect(c(0.5, 0.9), lab =expression(I[k]), radx = 0.05, rady = 0.1, cex = 1)
textrect(c(0.5, 0.2), lab =expression(I[a]), radx = 0.05, rady = 0.1, cex = 1)

textrect(mid=c(0.91, 0.9), lab =expression(R[k]),  radx = 0.05, rady = 0.1, cex = 1)
textrect(mid=c(0.91, 0.2), lab =expression(R[a]),  radx = 0.05, rady = 0.1, cex = 1)

textplain(mid=c(0.75, 0.55), lab ="Dead",  cex = 0.8)

textplain(mid=c(0.25, 0.81), 
          lab = expression(beta[kk]*I[k]*S[k] + beta[ka]*I[a]*S[k]), cex=0.5)

textplain(mid=c(0.25, 0.12), 
          lab = expression(beta[aa]*I[a]*S[a] + beta[ak]*I[k]*S[a]), cex=0.5)

textplain(mid=c(0.7, 0.81), lab = expression(gamma[k]*I[k]), cex=0.5)
textplain(mid=c(0.7, 0.12), lab = expression(gamma[a]*I[a]), cex=0.5)

textplain(mid=c(0.64, 0.75), lab = expression(alpha[k]*I[k]), cex=0.5)
textplain(mid=c(0.64, 0.35), lab = expression(alpha[a]*I[a]), cex=0.5)
```

To account for such a discrete difference in a model, we might simply create a second set of $S,I, \text{ and }R$ boxes for K-3 kids and adults. With the extra boxes (and resulting equations) we can thus allow things like contact rates or case fatality rates to differ between the groups. Of course we then need some additional parameters to allow for these different rates. In our example we went from three parameters in the basic $SIR$ model ($\beta, \gamma, \text{ and }, \alpha$) to eight in this kids vs. adults $SIR$: four $\beta$'s, two $\gamma$'s, and two $\alpha$'s. Why so many transmission perimeters? It is because kids can get infected from other kids or from adults and adults can get from other adults or from kids. This gives us the flexibility construct a model where, say, adults mostly infect adults, with a little going to kids, and kids infect each other a bit, but rarely infect adults, which broadly matches our current understanding of Covid-19 spread. 

A similar type of model has been used to understand the dynamics of measles in pre-vaccine era Great Britain^[This is a classic and fairly well-understood system thanks in large measure to the impressive record keeping in the U.K.], only most transmission seemed to go on in schools with little spillover into adults, who were mostly in the $R$ class anyway. Prior to broad-scale vaccination programs, there were many such "childhood" diseases including mumps and rubella. In some places with a high incidence of malaria, children are infected early in life. They experience the most severe symptoms, but develop partial immunity that can make subsequent infections less severe. In all of these cases it makes sense to consider children and adults separately.

There are many other ways we could divide up our populations that make sense in particular settings. We could consider males and females separately^[Males often have much higher burdens of macroparasites than females, perhaps because they move more or tend to have (seasonally) higher levels of testosterone, than can be immunosuppressive.], or hospital workers versus the general population^[Or by diet, environment, immunological history, behavior, ...]. In essence, this allows us to 1) better capture the groups that we think are important and 2) better understand how infection might cycle through, focus on, and impact particular groups of people or animals. It can also provide a platform with which to consider interventions focused on different compartments (e.g., what if we sent all of our young children to schools and summer camps and let the adults go back to work?^[Just wishful thinking...] 

There are two drawbacks to this approach. First, we are still assuming that within each of these smaller, more refined groups, everyone is identical. Sure, kids are different from adults, but every kid within the box is essentially the same as any other kid. And yes, we could makes lots and lots of boxes (e.g., one for each year of age?), but this brings us to the second drawback. These added categories come at the cost of many, many extra parameters. This results in more parameters that need to be pinned down or estimated, which is no small problem. But it also introduces complexity that makes it difficult to understand how the model works and what features are important or not. Moreover, and perhaps counter-intuitively, more complex models tend to generate _worse_ predictions^[Google or ask me about the bias-variance trade-off.]. There is no free lunch. 

# Thinking in terms of distributions

Sometimes, perhaps often, the differences among hosts are not clear and discrete, but graded and continuous. For instance, if we were to look at individual movement data (e.g., from cell phone records) we would undoubtedly see that some people, such as delivery drivers, are moving around quite a lot, even under stay-at-home orders while others never leave their homes. We could try to create boxes for home-delivery drivers versus others, but that would ignore the potentially important fact that even among the not-delivery drivers some people move very little, others more, and still others more than that. We cannot (easily) capture the _distribution_ of movement rates with a handful of distinct groups, as we have attempted so far. 

```{r, fig.margin=TRUE, fig.cap="Hypothetical data on movement rates of 250 individuals in a small town (grey bars) and two approaches to approximate these movement rates: 1) using two distinct groups (red lines) or 2) a statistical distribution (blue lines)."}
x=rlnorm(n=250, meanlog=1.25, sdlog=1.25)
ggplot(data.frame(x), aes(x=x)) + 
  geom_histogram() + 
  stat_function(fun = function(x) 250*dlnorm(x, meanlog=1.25, sdlog=1.25), 
                color="blue", n=5001)+
  geom_vline(xintercept = c(3,15), color="red") + 
  annotate(geom="text", x=c(4,16), y=c(60,15), 
           label=c("Not\ndelivery\ndriver", "Delivery\ndriver"),
           color="red", hjust=0, vjust=0) + 
  labs(x="Distance moved (km/day)", y="Number of people")
```

Instead, we might assume that some key parameter in a model is not a single fixed value, but rather comes from a distribution of values. Every individual in the population of interest can be thought of us having a value that is a random draw from that distribution. In our example with movement rates, most individuals would end up with draws from the low end of the distribution, but there would be a few that had much higher rates of movement. 

This kind of thinking simplifies things in some respects---we actually need fewer parameters to describe a distribution^[Usually just two, like a mean and a variance] than we would with extra boxes---but complicates them in others. For instance, goodbye most simple analytic solutions! Let me elide over the mathematics^[I know you're disappointed! Yeah math!]---suffice to say that there are a variety of approaches to dealing with models that allow for heterogeneity in classes or boxes^[Individual-based models and Integral Projection models, to name two]. Rather let us focus on the outcomes of thinking in terms of distributions. 

# Distributions of burdens: the 80:20 "rule"
One of the cooler features of thinking about distributions is that we can consider the distribution of, say, _intensities_ of infections. That is to say, some individuals have very mild infections while others have very intense infections. This is particularly important when considering macroparasites---larger, generally eukaryotic parasites that can, at least in principle, be counted^[Examples include ticks on a host or helminths within a host]. The severity of an infection, that is, the degree of morbidity and mortality, tends to increase with the number of these parasites in or on the host, which is called its burden or infection intensity. So it would not be very accurate to think of infected vs. not-infected, but rather we need to keep track of _how many_ parasites are in or on a host. 

When researchers have studied the distribution of macroparasites in hosts, including in humans, we usually observe a very skewed distribution. Most individuals have very low burdens, but some small fraction have very intense infections. Consider the Lyme disease agent-carrying black-legged ticks, _Ixodes scapularis_. Most larval and nymphal ticks feed on mice and other 
small mammals. During the peak activity of larval ticks a mouse might have an average of 5--20 larval ticks feeding on it, but most have fewer than that and few individuals have 150 or 200! 

[This pattern is very common](http://www.lancaster.ac.uk/staff/wilsonk4/publications-files/WilsonGrenfellShaw1996FuncEcol_aggregatedParasites.pdf), so much so that many simply refer to it as the 80:20 "rule"^[Although it really comes from an economic analysis of land ownership in Italy in the 1890's. It is also called the [Pareto principle](https://en.wikipedia.org/wiki/Pareto_principle) and shows up all over the place.] where 80% (or more!) of parasites in a population can be found in 20% (or less) of the hosts. It is actually not a rule, per se, but a frequently observed phenomenon. Unfortunately, there are many potential causes for this concentration of most parasites on a relative few, which makes it difficult to understand^[I [analyzed tick burdens on mice and chipmunks](https://www.researchgate.net/publication/23191519_Multiple_causes_of_variable_tick_burdens_on_small-mammal_hosts), hoping to find the "smoking gun" as to which individuals were so heavily parasitized. I found as many "guns" as variables that had been measured!]. For instance, if parasites reproduce on/in hosts, they tend to accumulate on a relative few. If being parasitized makes one more easily infected by more of the same parasite, that tends to aggregate parasites on certain hosts. Or it might just be ["bad luck"](https://www.researchgate.net/publication/51981608_Partitioning_the_Aggregation_of_Parasites_on_Hosts_into_Intrinsic_and_Extrinsic_Components_via_an_Extended_Poisson-Gamma_Mixture_Model).

Whatever the underlying cause, acknowledging that infections vary in their intensity leads to a rather different perspective on how disease works and spreads. It suggests that most of the impacts will fall on a smaller subset of the hosts. I also suggests that only those interventions that focus on this more heavily burdened hosts will have much success, but those that can target this small subset of hosts will be very efficient. Thus, there has been a great deal of work on trying to identify who these hosts are.

One final note on distributions. Researchers are increasingly coming to recognize that even microparasites---viruses, bacteria, fungi, and other very small, very numerous and rapidly growing parasites---can act like macroparasites where the intensity of infection deterimines the outcome of the infection. The fungal parasites of amphibians, _Batrachochytrium dendrobatidis_ (Bd^[Bd has caused population declines and even extinctions in hundreds of amphibian species. It is quite probably the most devastating pathogen yet known to science!]) and _B. salimandrivorans_ (Bsal), cause dose-dependent mortality. Indeed, there was for sometime^[Such simple rules of thumb do not often fair well when applied to different species in different settings and so on.] a 10,000 zoospore rule (zoospores are the mobile, infectious stage of Bd) where frogs with lower numbers of Bd zoospores tended to fair pretty well, but when the Bd population grew above this rough threshold, look out! The viruses I study in amphibians, ranaviruses, also seem to have a strong intensity-dependent component to them. (More on this later.) But perhaps the importance of infection intensity is most urgent in understanding the variety of outcomes of Covid-19 cases. Those individuals with high titers of circulating virus in them tend to have more severe symptoms and worse outcomes than those with lower, sometimes borderline detectable titers.  

# Super spreaders and super spreading events

The intensity of an individual's infection also predicts that individual's infectiousness to others, all else equal^[There are always other forces at work, but I am trying to simplify things to draw out the key principles. So "all else equal" means, ignoring other things for the moment.]. I will discuss dose-dependence elsewhere, but for now we can intuit that mild infections with lower numbers of parasites (e.g., SARS-CoV-2 virus particles) tend to shed fewer infectious particles and are thus less likely to infect someone else given a contact (e.g., being in the same room for 10 minutes) than someone with a more severe infection. Thus we avoid people that look sick^[As do most animals.]. 

Sometimes, however, a person might be shedding lots of infectious particles without acting or feeling sick^[One of the key difference between the current SARS-Cov-2 virus and the previous SARS-CoV-1 is that this new one [gets spread for several days before a person has symptoms](https://www.nytimes.com/2020/08/06/health/coronavirus-asymptomatic-transmission.html). This makes it much more difficult to control!]. They are mobile and infectious and well suited to infecting others. The classic example is [Mary Mallon](https://en.wikipedia.org/wiki/Mary_Mallon), known as "Typhoid Mary," who was the first and most publicly visible example of an asymptomatic carrier. While there were others, predominantly men, who were discovered to have inadvertently infected many more than Mary^[Two more complete, and highly engaging accounts, were made by [RadioLab](https://www.wnycstudios.org/podcasts/radiolab/episodes/169879-patient-zero) and [Throughline](https://www.npr.org/2020/06/23/882115755/theres-something-about-mary).], we still look back at her as the epitome of a "super spreader."

The term super spreader is an poorly defined and broadly misused term, but might operationally define it as an individual host who causes more secondary infections than one would expect. Since there is a distribution of secondary cases, some have operationalized this as something like "beyond the 99th percentile" of the distribution. Anyway, you'll certainly hear this term; just focus on what a person means and ignore the implication that is a particular type of person or discrete thing. It is best thought of as an extreme outcome.

What causes these extreme amounts of secondary infections? Well, the short version is superspreaders either make a lot of potentially infectious contacts ($c(N)$ in our prior models) or are especially infectious given a contact ($\pi$), but we have almost no way of knowing in most cases. It is probably often some degree of both. Indeed, we often refer to "super spreading events" because it is not clear if an unusually large cluster was due to something about the infected person (e.g., a nursing aid shedding lots of virus while feeling relatively healthy) or the situation (e.g., the fact that people in a nursing home are in such close quarters)^[Models suggest that that [superspreaders were in the wrong place at their most infectious time](https://www.nytimes.com/2020/08/07/health/coronavirus-superspreading-contagion.html). ]. The consequences of super spreading, however, are pretty clear. 

In both SARS outbreaks [super spreading events](https://www.nytimes.com/2020/06/02/opinion/coronavirus-superspreaders.html) are responsible for a [large fraction of the transmission](https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html#clusters). Indeed, in the first SARS outbreak in 2003 a handful of super spreading events fed the epidemic; without them the outbreak would have fizzled. In fact, this is a general result^[This is from one of my [favorite papers from a colleauge, Jamie Lloyd-Smith](https://www.researchgate.net/publication/7476817_Superspreading_and_the_Effect_of_Individual_Variation_on_Disease_Emergence).]: when the distribution of infectiousness is skewed such that there are super spreaders, most introductions sputter out, but a few lead to big clusters. That is, most people just are not that infectious (or just do not have enough potentially infectious contacts), but a small number of infections more than make up for it, causing large outbreaks. In that first SARS outbreak, the infection was introduced dozens of times all around the world, but outside of Singapore and China only introduction really took off! 



# Final thoughts


```{r, fig.margin=FALSE, fig.cap="The proportion of secondary infections attributed to the most infectious 20 percent of cases. From [Galvani and May. 2005. Nature 438:293-295.](https://pubmed.ncbi.nlm.nih.gov/16292292/)"}

knitr::include_graphics("Heterogeneity_Infectiousness.png", dpi=400)
```

What is true for SARS (both of them) is true for many other infections. For reasons we usually do not understand, some infected individuals cause a lot more secondary infections than average. This gives a sort of boom or bust^[Boom or fizzle?] set of outcomes that makes it more difficult to predict what will happen next, where the next hot spot might be, or even whether we have an epidemic under control.  It can also help us make sense of the large collection of seemingly contradictory anecdotes we read about. Why do many gatherings seem to cause little or no secondary infections while others end up causing a [cluster of infections](https://www.nytimes.com/2020/03/23/us/coronavirus-westport-connecticut-party-zero.html)? Both outcomes are real, but rather than expecting consistent outcomes in similar situations, perhaps we should be thinking instead about a wide range of potential outcomes. 

It is also worth noting that while we have focused on transmission, most aspects of infectious disease are variable and thus most parameters in a model might be best thought of in terms of distributions. For instance, the many anecdotes about a person testing positive for Covid-19 twice, several weeks apart, often with a second, worse onset of symptoms, [probably do not indicate a second infection](https://www.nytimes.com/2020/07/22/health/covid-antibodies-herd-immunity.html). Rather, they are probably just infections that lasted much longer than the average^[Sometimes viruses and other parasites hide out in particular tissues or go quiescent for a period of time.]^[Although there is now many clear cases of re-infection with genetically distinct strains of SARS-CoV-2]; that's normal and completely expected. 

The real world is heterogeneous and so you might think about with disdain the many epidemiological (and other) models that ignore this heterogeneity. After all, they are _clearly_ missing biological realities. While I agree with this sentiment, I also want to caution you not to throw out the baby with the bathwater. Models are not meant to incorporate every aspect of reality; they are simplifications of reality^[Caricatures?] that are (or usually should be) simple enough to understand. And remember, when they fail to capture the main features of a system, like the way an infection spreads, one can learn a lot by figuring out what feature(s) of the real world are needed to fix things. When a standard SIR model and one with a distribution of infectiousness diverge a great deal, that tells you that heterogeneity is doing something important. And that, inevitably, leads you to the next question: _Why?_


